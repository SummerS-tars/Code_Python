{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1fa46d",
   "metadata": {},
   "source": [
    "## Step 0: 生成“脏”数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境依赖\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建原始字典数据 (对应上午的学习内容：理解字典到DataFrame的转换)\n",
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 102, 105, 106, 107, 108, 109],  # 注意 102 重复了\n",
    "    'Branch': ['Beijing_A', 'Shanghai_B', 'Beijing_A', 'Shenzhen_C', 'Shanghai_B', \n",
    "               'Beijing_A', 'Shenzhen_C', 'Shanghai_B', 'Beijing_A', 'Shenzhen_C'],\n",
    "    'Product': ['Latte', 'Espresso', 'Cappuccino', 'Latte', 'Espresso', \n",
    "                'Mocha', 'Latte', 'Espresso', 'Latte', 'Mocha'],\n",
    "    'Price': [30.0, 25.0, 32.0, 30.0, 25.0, np.nan, 30.0, 25.0, 30.0, np.nan], # 有缺失值\n",
    "    'Quantity': [1, 2, 1, 3, 2, 2, 1, 5, 2, 1],\n",
    "    'Date': ['2023-10-01'] * 10\n",
    "}\n",
    "\n",
    "# 创建 DataFrame\n",
    "df_initial = pd.DataFrame(data)\n",
    "\n",
    "# 保存为 CSV (对应中午的学习内容：数据加载)\n",
    "df_initial.to_csv('dirty_coffee_sales.csv', index=False)\n",
    "\n",
    "print(\"项目数据 'dirty_coffee_sales.csv' 已生成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004fd71",
   "metadata": {},
   "source": [
    "## Step 1: 基础了解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理解数据基本形态\n",
    "ser_product = pd.Series(data=data['Product'])\n",
    "print(\"任务 A: 手动创建的 Product 列 Series:\")\n",
    "ser_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8189bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .loc 找出标签（索引）为 3 的那行数据\n",
    "print(\"任务 B: 使用 .loc 找出标签为 3 的那行数据:\")\n",
    "df_initial.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .iloc 找出前 5 行、前 2 列的数据\n",
    "print(\"任务 B: 使用 .iloc 找出前 5 行、前 2 列的数据:\")\n",
    "df_initial.iloc[:5, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe734e6f",
   "metadata": {},
   "source": [
    "## Step 2: 数据加载与预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394574f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dirty_coffee_sales.csv')\n",
    "print(\"数据预览:head():\")\n",
    "df.head()\n",
    "print(\"数据预览:info():\")\n",
    "df.info()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3bb98",
   "metadata": {},
   "source": [
    "## Step 3: 数据清洗与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 A: 处理重复值\")\n",
    "df.duplicated()\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值\n",
    "print(\"任务 B: 处理缺失值\")\n",
    "df = df.fillna({'Prive': 35.0}) # 假设摩卡的价格为35.0 + 字典赋值改进\n",
    "df.isna().sum() # 输出每个Series的缺失值数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57206f2",
   "metadata": {},
   "source": [
    "### fillna() 实践\n",
    "\n",
    "这里我们一开始直接使用了 `df.fillna(35.0)`  \n",
    "但是这会导致所有缺失值都被填充为 35.0  \n",
    "显然不是我们想要的结果  \n",
    "那么我们实际上是想要 `Price` 列的缺失值被填充为 35.0  \n",
    "因此我们可以使用字典来指定每一列的填充值  \n",
    "此外，这还支持多`Series`同时填充不同的值  \n",
    "\n",
    "```python\n",
    "df = df.fillna({'Price': 35.0})\n",
    "```\n",
    "\n",
    "另一种方法就是只填充和更新 `Price` 列的缺失值  \n",
    "\n",
    "```python\n",
    "df['Price'] = df['Price'].fillna(35.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理：获得每单总价\n",
    "df['Total_Price'] = df['Price'] * df['Quantity']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ee7b4",
   "metadata": {},
   "source": [
    "## Step 4: 数据聚合与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b20c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 A: 数据聚合 - 按分店统计总销售额\")\n",
    "df.groupby('Branch')['Total_Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 B: 数据透视表 - 每个分店每种产品的总销售额\")\n",
    "(\n",
    "    df.groupby(['Branch', 'Product'], as_index=False) # 使用as_index=False可以避免多级索引（也就是两个列名组合的元组作为行索引）\n",
    "        .agg(Total_Price=('Total_Price', 'sum'))\n",
    "        .sort_values(['Branch', 'Total_Price'], ascending=[True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284fdf4",
   "metadata": {},
   "source": [
    "### agg() 函数介绍\n",
    "\n",
    "`agg()` 函数实际上和数据库中学过的聚合函数非常类似  \n",
    "那么我们一般会遵循：“分组(groupby) -> 聚合(agg)” 的思路来进行数据的汇总与分析  \n",
    "\n",
    "常用用法：  \n",
    "\n",
    "- 单列单函数：  \n",
    "    `.agg(Total_Price=('Total_Price', 'sum'))`\n",
    "- 多列多函数：（推荐“命名聚合”方式）  \n",
    "    `.agg(NewCol=('col', 'func'), ...)`\n",
    "    支持多个NewCol，分别对应各自的列col和函数func\n",
    "- 多函数列表：  \n",
    "    `.agg({'col': ['func1', 'func2', ...]})`\n",
    "    这种方式会生成多级列名  \n",
    "\n",
    "func 用字符串时代表 Pandas 内置的聚合函数名。常见的有：\n",
    "\n",
    "- sum, mean, median\n",
    "- min, max, prod\n",
    "- count, size, nunique\n",
    "- std, var, sem\n",
    "- first, last\n",
    "- quantile, skew, kurt\n",
    "\n",
    "也可以传入自定义函数或 numpy 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Branch', as_index=False).agg(\n",
    "    Total_Price_Sum=('Total_Price', 'sum'),\n",
    "    Total_Price_Mean=('Total_Price', 'mean'),\n",
    "    Quantity_Sum=('Quantity', 'sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05156844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Branch').agg({'Total_Price': ['sum', 'mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc465e0",
   "metadata": {},
   "source": [
    "### `pivot_table()`: 数据透视表的另外一种方式\n",
    "`pivot_table()` 函数可以看作是 `groupby()` + `agg()` 的简化版  \n",
    "\n",
    "**使用介绍：**\n",
    "\n",
    "用于把数据\"透视\"成二维表格（行×列），并对交叉区域做聚合。  \n",
    "本质上是 groupby + agg + reshape 的快捷写法。\n",
    "\n",
    "**关键参数：**\n",
    "\n",
    "- `index`：行标签（分组行）\n",
    "- `columns`：列标签（分组列）\n",
    "- `values`：要汇总的数值列\n",
    "- `aggfunc`：聚合函数（如 sum、mean）\n",
    "- `fill_value`：空值填充\n",
    "\n",
    "**实践规范：**\n",
    "\n",
    "- `values` 只放数值列，避免混合类型导致异常。\n",
    "- `aggfunc` 明确指定（不要依赖默认 mean）。\n",
    "- 需要整洁输出时使用 `fill_value` 补 0。\n",
    "- 结果用于报表时,优先 `pivot_table`；用于进一步计算时,优先 `groupby` + `agg`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9791385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(\n",
    "    index='Branch',      # 行标签\n",
    "    columns='Product',   # 列标签 (这样产品名会横向展开，对比更清晰)\n",
    "    values='Total_Price',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0         # 没卖出的填0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
