{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1fa46d",
   "metadata": {},
   "source": [
    "## Step 0: 生成“脏”数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境依赖\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建原始字典数据 (对应上午的学习内容：理解字典到DataFrame的转换)\n",
    "data = {\n",
    "    'Transaction_ID': [101, 102, 103, 104, 102, 105, 106, 107, 108, 109],  # 注意 102 重复了\n",
    "    'Branch': ['Beijing_A', 'Shanghai_B', 'Beijing_A', 'Shenzhen_C', 'Shanghai_B', \n",
    "               'Beijing_A', 'Shenzhen_C', 'Shanghai_B', 'Beijing_A', 'Shenzhen_C'],\n",
    "    'Product': ['Latte', 'Espresso', 'Cappuccino', 'Latte', 'Espresso', \n",
    "                'Mocha', 'Latte', 'Espresso', 'Latte', 'Mocha'],\n",
    "    'Price': [30.0, 25.0, 32.0, 30.0, 25.0, np.nan, 30.0, 25.0, 30.0, np.nan], # 有缺失值\n",
    "    'Quantity': [1, 2, 1, 3, 2, 2, 1, 5, 2, 1],\n",
    "    'Date': ['2023-10-01'] * 10\n",
    "}\n",
    "\n",
    "# 创建 DataFrame\n",
    "df_initial = pd.DataFrame(data)\n",
    "\n",
    "# 保存为 CSV (对应中午的学习内容：数据加载)\n",
    "df_initial.to_csv('dirty_coffee_sales.csv', index=False)\n",
    "\n",
    "print(\"项目数据 'dirty_coffee_sales.csv' 已生成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004fd71",
   "metadata": {},
   "source": [
    "## Step 1: 基础了解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理解数据基本形态\n",
    "ser_product = pd.Series(data=data['Product'])\n",
    "print(\"任务 A: 手动创建的 Product 列 Series:\")\n",
    "ser_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8189bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .loc 找出标签（索引）为 3 的那行数据\n",
    "print(\"任务 B: 使用 .loc 找出标签为 3 的那行数据:\")\n",
    "df_initial.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .iloc 找出前 5 行、前 2 列的数据\n",
    "print(\"任务 B: 使用 .iloc 找出前 5 行、前 2 列的数据:\")\n",
    "df_initial.iloc[:5, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe734e6f",
   "metadata": {},
   "source": [
    "## Step 2: 数据加载与预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394574f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dirty_coffee_sales.csv')\n",
    "print(\"数据预览:head():\")\n",
    "display(df.head())\n",
    "print(\"数据预览:info():\")\n",
    "display(df.info())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3bb98",
   "metadata": {},
   "source": [
    "## Step 3: 数据清洗与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 A: 处理重复值\")\n",
    "display(df.duplicated())\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值\n",
    "print(\"任务 B: 处理缺失值\")\n",
    "df = df.fillna({'Price': 35.0}) # 假设摩卡的价格为35.0 + 字典赋值改进\n",
    "df.isna().sum() # 输出每个Series的缺失值数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57206f2",
   "metadata": {},
   "source": [
    "### fillna() 实践\n",
    "\n",
    "这里我们一开始直接使用了 `df.fillna(35.0)`  \n",
    "但是这会导致所有缺失值都被填充为 35.0  \n",
    "显然不是我们想要的结果  \n",
    "那么我们实际上是想要 `Price` 列的缺失值被填充为 35.0  \n",
    "因此我们可以使用字典来指定每一列的填充值  \n",
    "此外，这还支持多`Series`同时填充不同的值  \n",
    "\n",
    "```python\n",
    "df = df.fillna({'Price': 35.0})\n",
    "```\n",
    "\n",
    "另一种方法就是只填充和更新 `Price` 列的缺失值  \n",
    "\n",
    "```python\n",
    "df['Price'] = df['Price'].fillna(35.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理：获得每单总价\n",
    "df['Total_Price'] = df['Price'] * df['Quantity'] # 向量化操作，底层实现比循环高效很多\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ee7b4",
   "metadata": {},
   "source": [
    "## Step 4: 数据聚合与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b20c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 A: 数据聚合 - 按分店统计总销售额\")\n",
    "display(df.groupby('Branch')['Total_Price'].sum())\n",
    "# display(df.groupby('Branch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"任务 B: 数据透视表 - 每个分店每种产品的总销售额\")\n",
    "( # 处理流太长了可以这样写，函数内参数也是一样\n",
    "    df.groupby(['Branch', 'Product'], as_index=False) # 使用as_index=False可以避免多级索引（也就是两个列名组合的元组作为行索引）\n",
    "        .agg(Total_Price=('Total_Price', 'sum'))\n",
    "        .sort_values(['Branch', 'Total_Price'], ascending=[True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284fdf4",
   "metadata": {},
   "source": [
    "### agg() 函数介绍\n",
    "\n",
    "`agg()` 函数实际上和数据库中学过的聚合函数非常类似  \n",
    "那么我们一般会遵循：“分组(groupby) -> 聚合(agg)” 的思路来进行数据的汇总与分析  \n",
    "\n",
    "常用用法：  \n",
    "\n",
    "- 单列单函数：  \n",
    "    `.agg(Total_Price=('Total_Price', 'sum'))`\n",
    "- 多列多函数：（推荐“命名聚合”方式）  \n",
    "    `.agg(NewCol=('col', 'func'), ...)`\n",
    "    支持多个NewCol，分别对应各自的列col和函数func\n",
    "- 多函数列表：  \n",
    "    `.agg({'col': ['func1', 'func2', ...]})`\n",
    "    这种方式会生成多级列名  \n",
    "\n",
    "func 用字符串时代表 Pandas 内置的聚合函数名。常见的有：\n",
    "\n",
    "- sum, mean, median\n",
    "- min, max, prod\n",
    "- count, size, nunique\n",
    "- std, var, sem\n",
    "- first, last\n",
    "- quantile, skew, kurt\n",
    "\n",
    "也可以传入自定义函数或 numpy 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Branch', as_index=False).agg(\n",
    "    Total_Price_Sum=('Total_Price', 'sum'),\n",
    "    Total_Price_Mean=('Total_Price', 'mean'),\n",
    "    Quantity_Sum=('Quantity', 'sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05156844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Branch').agg({'Total_Price': ['sum', 'mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc465e0",
   "metadata": {},
   "source": [
    "### `pivot_table()`: 数据透视表的另外一种方式\n",
    "`pivot_table()` 函数可以看作是 `groupby()` + `agg()` 的简化版  \n",
    "\n",
    "**使用介绍：**\n",
    "\n",
    "用于把数据\"透视\"成二维表格（行×列），并对交叉区域做聚合。  \n",
    "本质上是 groupby + agg + reshape 的快捷写法。\n",
    "\n",
    "**关键参数：**\n",
    "\n",
    "- `index`：行标签（分组行）\n",
    "- `columns`：列标签（分组列）\n",
    "- `values`：要汇总的数值列\n",
    "- `aggfunc`：聚合函数（如 sum、mean）\n",
    "- `fill_value`：空值填充\n",
    "\n",
    "**实践规范：**\n",
    "\n",
    "- `values` 只放数值列，避免混合类型导致异常。\n",
    "- `aggfunc` 明确指定（不要依赖默认 mean）。\n",
    "- 需要整洁输出时使用 `fill_value` 补 0。\n",
    "- 结果用于报表时,优先 `pivot_table`；用于进一步计算时,优先 `groupby` + `agg`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9791385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(\n",
    "    index='Branch',      # 行标签\n",
    "    columns='Product',   # 列标签 (这样产品名会横向展开，对比更清晰)\n",
    "    values='Total_Price',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0         # 没卖出的填0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f108db19",
   "metadata": {},
   "source": [
    "## Step 5: 新数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29311087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成产品价格表 (Master Table)\n",
    "# 这是一个标准的“字典表”\n",
    "df_products = pd.DataFrame({\n",
    "    'Product': ['Latte', 'Espresso', 'Cappuccino', 'Mocha'],\n",
    "    'Base_Price': [30.0, 25.0, 32.0, 35.0],  # 摩卡的官方价格是 35\n",
    "    'Category': ['Milk Coffee', 'Black Coffee', 'Milk Coffee', 'Chocolate Coffee']\n",
    "})\n",
    "\n",
    "print(\"产品主数据 (df_products):\")\n",
    "display(df_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76554a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了演示时间分析，我们需要稍微“篡改”一下之前的 df，让它包含不同的日期\n",
    "# 假设这 9 笔订单发生在不同的 3 天里\n",
    "df['Date'] = ['2023-10-01', '2023-10-01', '2023-10-01', \n",
    "              '2023-10-02', '2023-10-02', '2023-10-02', # 10-02 是周一\n",
    "              '2023-10-07', '2023-10-07', '2023-10-07'] # 10-07 是周六\n",
    "print(\"\\n更新后的订单表 (Date 已修改):\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febda368",
   "metadata": {},
   "source": [
    "## Step 6: 关联数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df_products, how='left', on='Product')\n",
    "\n",
    "print(\"\\n关联后的订单表 (df_merged):\")\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更改price模拟错误\n",
    "df_merged.loc[df_merged['Transaction_ID'] == 105, 'Price'] = 33.0\n",
    "\n",
    "# 同步更新派生列\n",
    "df_merged['Total_Price'] = df_merged['Price'] * df_merged['Quantity']\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据完整性\n",
    "mask_error = df_merged['Price'] != df_merged['Base_Price'] # 此处mask_error也是Series，不过是布尔类型，与表同长（及rows数量相同）\n",
    "if mask_error.any():\n",
    "    print(\"发现价格不匹配的记录:\")\n",
    "    display(df_merged[mask_error]) # 布尔索引筛选，只保留True的行\n",
    "else:\n",
    "    print(\"所有价格均匹配。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果考虑修复数据\n",
    "mask_error = df_merged['Price'] != df_merged['Base_Price']\n",
    "df_merged.loc[mask_error, 'Price'] = df_merged.loc[mask_error, 'Base_Price']\n",
    "\n",
    "# 同步更新派生列（只更新错误行）\n",
    "df_merged.loc[mask_error, 'Total_Price'] = (\n",
    "    df_merged.loc[mask_error, 'Price'] * df_merged.loc[mask_error, 'Quantity']\n",
    ")\n",
    "\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2d3a9",
   "metadata": {},
   "source": [
    "## Step 7: 时间序列处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa07dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 转换类型 Parsing\n",
    "df_merged['Date'] = pd.to_datetime(df_merged['Date']) # 直接替换为日期时间类型的Series\n",
    "\n",
    "# 2. 提取特征\n",
    "# .dt为datetime类型专属访问器\n",
    "df_merged['Weekday_Name'] = df_merged['Date'].dt.day_name() # 星期的全名\n",
    "df_merged['Is_Weekend'] = df_merged['Date'].dt.weekday >= 5  # Saturday=5, Sunday=6\n",
    "\n",
    "print(\"\\n含时间特征的订单表 (df_merged):\")\n",
    "print(\"\\nDate 列的数据类型：\", df_merged['Date'].dtype)\n",
    "display(df_merged[['Date', 'Weekday_Name', 'Is_Weekend']].head()) # 注意有两中括号，表示显示内层列表中的几个列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b909ad",
   "metadata": {},
   "source": [
    "## Step 8: 进阶分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbaf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"分析1：周末和工作日的平均客单量\")\n",
    "report_weekend = df_merged.pivot_table(\n",
    "    index='Is_Weekend',\n",
    "    values='Total_Price',\n",
    "    aggfunc=['sum', 'mean', 'count'] # type: ignore\n",
    ")\n",
    "display(report_weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n分析 2: 各产品类别的销售占比\")\n",
    "category_sales = df_merged.groupby('Category')['Total_Price'].sum()\n",
    "display(category_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc42bb",
   "metadata": {},
   "source": [
    "## Step 9: 趋势分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c5031",
   "metadata": {},
   "source": [
    "### Pandas 原生写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82088e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期整合数据\n",
    "daily_revenue = df_merged.groupby('Date')['Total_Price'].sum()\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(10, 5)) # 设置画布大小\n",
    "daily_revenue.plot(\n",
    "    kind='line',\n",
    "    marker='o',\n",
    "    color='tab:blue',\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "plt.title('Daily Revenue Trend', fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (CNY)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
